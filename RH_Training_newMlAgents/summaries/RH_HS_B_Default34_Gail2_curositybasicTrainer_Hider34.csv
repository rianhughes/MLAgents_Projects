Steps,Policy/Entropy,Policy/Learning Rate,Policy/Extrinsic Value Estimate,Policy/Extrinsic Reward,Environment/Cumulative Reward,Environment/Episode Length
10000,1.4189383,0.0002970003,0.07923388,3.5071632862091064,3.5071632756385953,1860.2
20000,1.4189161,0.00029100032,0.08563716,2.3383587021380663,2.3383586950755366,1377.6666666666667
30000,1.4183378,0.00028500034,0.09627071,2.952761957687991,2.952761943950983,1611.857142857143
40000,1.4178382,0.00027900032,0.09958303,1.7503947303630412,1.7503947278892156,1204.75
50000,1.4182866,0.00027300033,0.10685511,3.4351335478325686,3.4351335340955607,1755.0
60000,1.41867,0.00026700032,0.114849776,1.2059959642589093,1.2059959973674268,1609.4
70000,1.4193459,0.00026100036,0.11370133,2.3159401598386467,2.315940159431193,1363.25
80000,1.419717,0.00025500034,0.11600151,2.3938289172947407,2.3938289103098214,1395.8333333333333
90000,1.4198542,0.00024900032,0.10742238,1.4699462000280619,1.4699461590498686,1505.375
100000,1.4200319,0.00024300034,0.114624664,1.3777650882090842,1.3777650902047753,1106.5714285714287
110000,1.4198732,0.00023700035,0.12401694,2.7496073559990952,2.7496073483822068,1511.4285714285713
120000,1.4197018,0.00023100035,0.122311406,1.9734973547359307,1.9734973498464872,1241.5555555555557
130000,1.4195608,0.00022500036,0.1279551,2.3071336994568505,2.307133696973324,1361.0
140000,1.4196872,0.00021900034,0.12317977,2.350691322237253,2.3506913200835697,1376.75
