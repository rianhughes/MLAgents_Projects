Steps,Policy/Entropy,Policy/Learning Rate,Policy/Extrinsic Value Estimate,Policy/Extrinsic Reward,Environment/Cumulative Reward,Environment/Episode Length
10000,1.4189383,0.0002970003,0.078960985,-3.5071632862091064,-3.5071632756385953,1860.2
20000,1.418539,0.00029100032,0.044125274,-2.3383587021380663,-2.3383586950755366,1377.6666666666667
30000,1.4180645,0.00028500034,0.022092924,-2.952761957687991,-2.952761943950983,1611.857142857143
40000,1.4184384,0.00027900032,0.0035384046,-1.7503947303630412,-1.7503947278892156,1204.75
50000,1.4182031,0.00027300033,-0.020155782,-3.4351335478325686,-3.4351335340955607,1755.0
60000,1.4184109,0.00026700032,-0.03922149,-1.2059959642589093,-1.2059959973674268,1609.4
70000,1.4186378,0.00026100036,-0.05150828,-2.3159401598386467,-2.315940159431193,1363.25
80000,1.4195889,0.00025500034,-0.06309359,-2.3938289172947407,-2.3938289103098214,1395.8333333333333
90000,1.4202684,0.00024900032,-0.07341244,-1.4699462000280619,-1.4699461590498686,1505.375
100000,1.4203407,0.00024300034,-0.08381184,-1.3777650882090842,-1.3777650902047753,1106.5714285714287
110000,1.4200096,0.00023700035,-0.08785634,-2.7496073559990952,-2.7496073483822068,1511.4285714285713
120000,1.4196591,0.00023100035,-0.08658823,-1.9734973547359307,-1.9734973498464872,1241.5555555555557
130000,1.4193166,0.00022500036,-0.096459605,-2.3071336994568505,-2.307133696973324,1361.0
140000,1.419336,0.00021900034,-0.10598705,-2.350691322237253,-2.3506913200835697,1376.75
